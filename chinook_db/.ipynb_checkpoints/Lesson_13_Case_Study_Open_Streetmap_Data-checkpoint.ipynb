{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!DOCTYPE': 2,\n",
      " '?brief-description-of-drawings': 7,\n",
      " '?xml': 2,\n",
      " 'additional-info>unstructured</additional-info>': 3,\n",
      " 'address>': 19,\n",
      " 'addressbook>': 19,\n",
      " 'agent': 4,\n",
      " 'agents>': 3,\n",
      " 'application-reference': 3,\n",
      " 'assignee>': 2,\n",
      " 'assignees>': 2,\n",
      " 'assistant-examiner>': 1,\n",
      " 'category>cited': 74,\n",
      " 'child-doc>': 0,\n",
      " 'city>Alpine</city>': 1,\n",
      " 'city>Augusta</city>': 1,\n",
      " 'city>Battle': 2,\n",
      " 'city>Kalamazoo</city>': 1,\n",
      " 'city>New': 0,\n",
      " 'city>Powder': 1,\n",
      " 'city>Shuitou': 0,\n",
      " 'city>Wenzhou</city>': 1,\n",
      " 'claim': 3,\n",
      " 'claim-text>The': 2,\n",
      " 'claim-text>We': 0,\n",
      " 'claims': 3,\n",
      " 'classification-locarno>': 3,\n",
      " 'classification-national>': 132,\n",
      " 'classification-national><country>US</country><main-classification>': 12,\n",
      " 'classification-national><country>US</country><main-classification>119710</main-classification></classification-national>': 9,\n",
      " 'classification-national><country>US</country><main-classification>206278</main-classification></classification-national>': 1,\n",
      " 'classification-national><country>US</country><main-classification>206284</main-classification></classification-national>': 0,\n",
      " 'classification-national><country>US</country><main-classification>223': 8,\n",
      " 'classification-national><country>US</country><main-classification>426': 4,\n",
      " 'classification-national><country>US</country><main-classification>426104</main-classification></classification-national>': 0,\n",
      " 'classification-national><country>US</country><main-classification>426132</main-classification></classification-national>': 0,\n",
      " 'classification-national><country>US</country><main-classification>431291</main-classification></classification-national>': 0,\n",
      " 'classification-national><country>US</country><main-classification>D': 18,\n",
      " 'classification-national><country>US</country><main-classification>D11157</main-classification></classification-national>': 0,\n",
      " 'classification-national><country>US</country><main-classification>D28': 2,\n",
      " 'classification-national><country>US</country><main-classification>D30160</main-classification></classification-national>': 4,\n",
      " 'continuation-in-part>': 0,\n",
      " 'country>CN</country>': 3,\n",
      " 'country>US</country>': 233,\n",
      " 'country>unknown</country>': 4,\n",
      " 'date>19020900</date>': 0,\n",
      " 'date>19290700</date>': 1,\n",
      " 'date>19301100</date>': 0,\n",
      " 'date>19310200</date>': 0,\n",
      " 'date>19340600</date>': 0,\n",
      " 'date>19530100</date>': 0,\n",
      " 'date>19580700</date>': 0,\n",
      " 'date>19610300</date>': 0,\n",
      " 'date>19621200</date>': 0,\n",
      " 'date>19650900</date>': 0,\n",
      " 'date>19660300</date>': 0,\n",
      " 'date>19680200</date>': 0,\n",
      " 'date>19690700</date>': 0,\n",
      " 'date>19750100</date>': 0,\n",
      " 'date>19860700</date>': 0,\n",
      " 'date>19880400</date>': 0,\n",
      " 'date>19890800</date>': 0,\n",
      " 'date>19931200</date>': 0,\n",
      " 'date>19940700</date>': 0,\n",
      " 'date>19960700</date>': 0,\n",
      " 'date>19970400</date>': 0,\n",
      " 'date>19981000</date>': 0,\n",
      " 'date>20000700</date>': 0,\n",
      " 'date>20000800</date>': 0,\n",
      " 'date>20010100</date>': 0,\n",
      " 'date>20020100</date>': 0,\n",
      " 'date>20020400</date>': 0,\n",
      " 'date>20021000</date>': 0,\n",
      " 'date>20030400</date>': 0,\n",
      " 'date>20030600</date>': 0,\n",
      " 'date>20030700</date>': 1,\n",
      " 'date>20030800</date>': 0,\n",
      " 'date>20030900</date>': 0,\n",
      " 'date>20040800</date>': 0,\n",
      " 'date>20040900</date>': 0,\n",
      " 'date>20041000</date>': 0,\n",
      " 'date>20050100</date>': 0,\n",
      " 'date>20051200</date>': 1,\n",
      " 'date>20061000</date>': 0,\n",
      " 'date>20070200</date>': 1,\n",
      " 'date>20070300</date>': 0,\n",
      " 'date>20070400</date>': 0,\n",
      " 'date>20071000</date>': 0,\n",
      " 'date>20090100</date>': 0,\n",
      " 'date>20090300</date>': 0,\n",
      " 'date>20090800</date>': 0,\n",
      " 'date>20090900</date>': 0,\n",
      " 'date>20100100</date>': 0,\n",
      " 'date>20100200</date>': 0,\n",
      " 'date>20100400</date>': 0,\n",
      " 'date>20101100</date>': 0,\n",
      " 'date>20110200</date>': 1,\n",
      " 'date>20110609</date>': 0,\n",
      " 'date>20110719</date>': 0,\n",
      " 'date>20110800</date>': 0,\n",
      " 'date>20110900</date>': 0,\n",
      " 'date>20111000</date>': 0,\n",
      " 'date>20111200</date>': 0,\n",
      " 'date>20120400</date>': 2,\n",
      " 'date>20120500</date>': 0,\n",
      " 'date>20120517</date>': 0,\n",
      " 'date>20120600</date>': 0,\n",
      " 'date>20120700</date>': 0,\n",
      " 'date>20120725</date>': 0,\n",
      " 'date>20120900</date>': 0,\n",
      " 'date>20121200</date>': 2,\n",
      " 'date>20130200</date>': 1,\n",
      " 'date>20130500</date>': 0,\n",
      " 'date>20130523</date>': 0,\n",
      " 'date>20140107</date>': 3,\n",
      " 'department>2911</department>': 1,\n",
      " 'department>2913</department>': 0,\n",
      " 'department>2916</department>': 0,\n",
      " 'description': 3,\n",
      " 'description-of-drawings>': 3,\n",
      " 'doc-number>1720009</doc-number>': 0,\n",
      " 'doc-number>1721333</doc-number>': 0,\n",
      " 'doc-number>1780418</doc-number>': 0,\n",
      " 'doc-number>1791638</doc-number>': 0,\n",
      " 'doc-number>1962600</doc-number>': 0,\n",
      " 'doc-number>2003/0157222</doc-number>': 0,\n",
      " 'doc-number>2005/0271775</doc-number>': 0,\n",
      " 'doc-number>2009/0004338</doc-number>': 0,\n",
      " 'doc-number>2011/0192869</doc-number>': 0,\n",
      " 'doc-number>2011/0262587</doc-number>': 0,\n",
      " 'doc-number>2012/0079992</doc-number>': 0,\n",
      " 'doc-number>2012/0082762</doc-number>': 0,\n",
      " 'doc-number>2012/0085296</doc-number>': 0,\n",
      " 'doc-number>2012/0186535</doc-number>': 0,\n",
      " 'doc-number>2012/0311759</doc-number>': 0,\n",
      " 'doc-number>2013/0047931</doc-number>': 0,\n",
      " 'doc-number>2013/0047932</doc-number>': 0,\n",
      " 'doc-number>2013/0133588</doc-number>': 0,\n",
      " 'doc-number>2625687</doc-number>': 0,\n",
      " 'doc-number>2844821</doc-number>': 0,\n",
      " 'doc-number>29393780</doc-number>': 0,\n",
      " 'doc-number>29397653</doc-number>': 0,\n",
      " 'doc-number>29422143</doc-number>': 0,\n",
      " 'doc-number>29428061</doc-number>': 1,\n",
      " 'doc-number>29455647</doc-number>': 0,\n",
      " 'doc-number>3069009</doc-number>': 0,\n",
      " 'doc-number>3204838</doc-number>': 0,\n",
      " 'doc-number>3243087</doc-number>': 0,\n",
      " 'doc-number>3370765</doc-number>': 0,\n",
      " 'doc-number>3456853</doc-number>': 0,\n",
      " 'doc-number>4601066</doc-number>': 0,\n",
      " 'doc-number>4737995</doc-number>': 0,\n",
      " 'doc-number>4860388</doc-number>': 0,\n",
      " 'doc-number>5328065</doc-number>': 0,\n",
      " 'doc-number>5539930</doc-number>': 0,\n",
      " 'doc-number>5620118</doc-number>': 0,\n",
      " 'doc-number>5826760</doc-number>': 0,\n",
      " 'doc-number>6105833</doc-number>': 0,\n",
      " 'doc-number>6178922</doc-number>': 0,\n",
      " 'doc-number>6371755</doc-number>': 0,\n",
      " 'doc-number>6468569</doc-number>': 0,\n",
      " 'doc-number>6840196</doc-number>': 0,\n",
      " 'doc-number>709680</doc-number>': 0,\n",
      " 'doc-number>7194981</doc-number>': 0,\n",
      " 'doc-number>7203974</doc-number>': 0,\n",
      " 'doc-number>7500559</doc-number>': 0,\n",
      " 'doc-number>7568577</doc-number>': 0,\n",
      " 'doc-number>7691426</doc-number>': 0,\n",
      " 'doc-number>8074609</doc-number>': 0,\n",
      " 'doc-number>D0696836</doc-number>': 0,\n",
      " 'doc-number>D0696837</doc-number>': 0,\n",
      " 'doc-number>D0696838</doc-number>': 0,\n",
      " 'doc-number>D0696839</doc-number>': 0,\n",
      " 'doc-number>D189899</doc-number>': 0,\n",
      " 'doc-number>D234099</doc-number>': 0,\n",
      " 'doc-number>D341919</doc-number>': 0,\n",
      " 'doc-number>D427416</doc-number>': 0,\n",
      " 'doc-number>D452988</doc-number>': 0,\n",
      " 'doc-number>D472682</doc-number>': 0,\n",
      " 'doc-number>D476137</doc-number>': 0,\n",
      " 'doc-number>D477693</doc-number>': 0,\n",
      " 'doc-number>D477695</doc-number>': 0,\n",
      " 'doc-number>D479369</doc-number>': 0,\n",
      " 'doc-number>D493604</doc-number>': 0,\n",
      " 'doc-number>D495467</doc-number>': 0,\n",
      " 'doc-number>D497240</doc-number>': 0,\n",
      " 'doc-number>D512199</doc-number>': 0,\n",
      " 'doc-number>D530483</doc-number>': 0,\n",
      " 'doc-number>D537562</doc-number>': 0,\n",
      " 'doc-number>D537563</doc-number>': 0,\n",
      " 'doc-number>D551826</doc-number>': 0,\n",
      " 'doc-number>D600426</doc-number>': 0,\n",
      " 'doc-number>D608060</doc-number>': 0,\n",
      " 'doc-number>D609877</doc-number>': 0,\n",
      " 'doc-number>D627137</doc-number>': 0,\n",
      " 'doc-number>D632212</doc-number>': 0,\n",
      " 'doc-number>D632842</doc-number>': 0,\n",
      " 'doc-number>D644817</doc-number>': 0,\n",
      " 'doc-number>D658348</doc-number>': 0,\n",
      " 'doc-number>D661466</doc-number>': 0,\n",
      " 'doc-number>D666381</doc-number>': 0,\n",
      " 'doc-number>D672527</doc-number>': 0,\n",
      " 'doc-number>D672528</doc-number>': 0,\n",
      " 'document-id>': 83,\n",
      " 'drawings': 3,\n",
      " 'edition>10</edition>': 3,\n",
      " 'examiners>': 3,\n",
      " 'figure': 18,\n",
      " 'figures>': 3,\n",
      " 'first-name>Bradley': 0,\n",
      " 'first-name>Cathron</first-name>': 1,\n",
      " 'first-name>Cin</first-name>': 1,\n",
      " 'first-name>Glenn</first-name>': 1,\n",
      " 'first-name>Karen': 0,\n",
      " 'first-name>Katie</first-name>': 1,\n",
      " 'first-name>Marilyn</first-name>': 1,\n",
      " 'first-name>Nathan</first-name>': 1,\n",
      " 'first-name>Rashida</first-name>': 0,\n",
      " 'first-name>Wei</first-name>': 1,\n",
      " 'first-name>Zuxi</first-name>': 1,\n",
      " 'further-classification>': 1,\n",
      " 'img': 18,\n",
      " 'invention-title': 3,\n",
      " 'inventor': 5,\n",
      " 'inventors>': 3,\n",
      " 'kind>A1</kind>': 12,\n",
      " 'kind>A</kind>': 20,\n",
      " 'kind>B1</kind>': 2,\n",
      " 'kind>B2</kind>': 6,\n",
      " 'kind>S1</kind>': 3,\n",
      " 'kind>S</kind>': 29,\n",
      " 'last-name>Brooks</last-name>': 1,\n",
      " 'last-name>Chen</last-name>': 1,\n",
      " 'last-name>Crose</last-name>': 0,\n",
      " 'last-name>Eldridge': 0,\n",
      " 'last-name>Harris</last-name>': 1,\n",
      " 'last-name>Johnson</last-name>': 0,\n",
      " 'last-name>Kim</last-name>': 1,\n",
      " 'last-name>Lu</last-name>': 1,\n",
      " 'last-name>Mroczka</last-name>': 1,\n",
      " 'last-name>Okrasinski</last-name>': 1,\n",
      " 'last-name>Quinlan</last-name>': 1,\n",
      " 'length-of-grant>14</length-of-grant>': 3,\n",
      " 'main-classification>': 36,\n",
      " 'main-classification>0101</main-classification>': 1,\n",
      " 'main-classification>0202</main-classification>': 0,\n",
      " 'main-classification>0205</main-classification>': 0,\n",
      " 'main-classification>119710</main-classification>': 0,\n",
      " 'main-classification>206278</main-classification>': 0,\n",
      " 'main-classification>206288</main-classification>': 0,\n",
      " 'main-classification>206289</main-classification>': 0,\n",
      " 'main-classification>206292</main-classification>': 0,\n",
      " 'main-classification>206495</main-classification>': 0,\n",
      " 'main-classification>223': 2,\n",
      " 'main-classification>248340</main-classification>': 0,\n",
      " 'main-classification>249117</main-classification>': 0,\n",
      " 'main-classification>249137</main-classification>': 0,\n",
      " 'main-classification>264259</main-classification>': 0,\n",
      " 'main-classification>426': 7,\n",
      " 'main-classification>426101</main-classification>': 0,\n",
      " 'main-classification>426103</main-classification>': 0,\n",
      " 'main-classification>426104</main-classification>': 0,\n",
      " 'main-classification>426108</main-classification>': 0,\n",
      " 'main-classification>426138-139</main-classification>': 0,\n",
      " 'main-classification>426143</main-classification>': 0,\n",
      " 'main-classification>426144</main-classification>': 0,\n",
      " 'main-classification>426279</main-classification>': 0,\n",
      " 'main-classification>426282</main-classification>': 0,\n",
      " 'main-classification>426283</main-classification>': 0,\n",
      " 'main-classification>426391</main-classification>': 0,\n",
      " 'main-classification>426503</main-classification>': 0,\n",
      " 'main-classification>426514</main-classification>': 0,\n",
      " 'main-classification>426549</main-classification>': 0,\n",
      " 'main-classification>426559</main-classification>': 0,\n",
      " 'main-classification>426560</main-classification>': 0,\n",
      " 'main-classification>426660</main-classification>': 0,\n",
      " 'main-classification>426808</main-classification>': 0,\n",
      " 'main-classification>D': 44,\n",
      " 'main-classification>D11': 5,\n",
      " 'main-classification>D11157</main-classification>': 0,\n",
      " 'main-classification>D11222</main-classification>': 0,\n",
      " 'main-classification>D21385</main-classification>': 0,\n",
      " 'main-classification>D21386</main-classification>': 0,\n",
      " 'main-classification>D28': 0,\n",
      " 'main-classification>D30160</main-classification>': 0,\n",
      " 'name>Adkins</name>': 0,\n",
      " 'name>Anderson': 0,\n",
      " 'name>Axelrod': 0,\n",
      " 'name>Campbell</name>': 0,\n",
      " 'name>Chen': 1,\n",
      " 'name>Cunningham</name>': 0,\n",
      " 'name>Dahl': 0,\n",
      " 'name>Dean</name>': 0,\n",
      " 'name>Dearth</name>': 0,\n",
      " 'name>Denesuk': 0,\n",
      " 'name>Dennison</name>': 0,\n",
      " 'name>DiStefano</name>': 0,\n",
      " 'name>Dunker': 0,\n",
      " 'name>Ergezinger': 0,\n",
      " 'name>Figg</name>': 0,\n",
      " 'name>Frudakis</name>': 0,\n",
      " 'name>Gobble</name>': 0,\n",
      " 'name>Grimes</name>': 0,\n",
      " 'name>Hanna': 0,\n",
      " 'name>Henry': 0,\n",
      " 'name>Hodge</name>': 0,\n",
      " 'name>Hoeflich</name>': 0,\n",
      " 'name>Ibanez</name>': 0,\n",
      " 'name>Jones': 0,\n",
      " 'name>Jossem</name>': 0,\n",
      " 'name>Kadow-Dougherty</name>': 0,\n",
      " 'name>Keavey': 0,\n",
      " 'name>Keys</name>': 0,\n",
      " 'name>Kim</name>': 5,\n",
      " 'name>Kirch': 1,\n",
      " 'name>Kirch</name>': 3,\n",
      " 'name>Kolton': 2,\n",
      " 'name>Lai</name>': 0,\n",
      " 'name>Lambert</name>': 0,\n",
      " 'name>Levine': 0,\n",
      " 'name>McCleary</name>': 0,\n",
      " 'name>McFarlane</name>': 0,\n",
      " 'name>Moore</name>': 0,\n",
      " 'name>Najarian</name>': 0,\n",
      " 'name>Pulitzer</name>': 1,\n",
      " 'name>Reynolds</name>': 0,\n",
      " 'name>Richman</name>': 0,\n",
      " 'name>Salmon': 0,\n",
      " 'name>Sesselmann</name>': 0,\n",
      " 'name>Sherman</name>': 1,\n",
      " 'name>Shurtz</name>': 0,\n",
      " 'name>Stamos': 0,\n",
      " 'name>Stern': 0,\n",
      " 'name>Stern</name>': 0,\n",
      " 'name>Taft</name>': 0,\n",
      " 'name>Taniguchi': 1,\n",
      " 'name>Taniguchi</name>': 0,\n",
      " 'name>Tepper': 2,\n",
      " 'name>Tu</name>': 0,\n",
      " 'name>Weinberg': 0,\n",
      " 'name>Wiley</name>': 0,\n",
      " 'name>Willoughby</name>': 0,\n",
      " 'nplcit': 0,\n",
      " 'number-of-claims>1</number-of-claims>': 3,\n",
      " 'number-of-drawing-sheets>2</number-of-drawing-sheets>': 1,\n",
      " 'number-of-drawing-sheets>5</number-of-drawing-sheets>': 0,\n",
      " 'number-of-drawing-sheets>6</number-of-drawing-sheets>': 0,\n",
      " 'number-of-figures>4</number-of-figures>': 0,\n",
      " 'number-of-figures>6</number-of-figures>': 0,\n",
      " 'number-of-figures>7</number-of-figures>': 0,\n",
      " 'number-of-figures>9</number-of-figures>': 0,\n",
      " 'orgname>Crose': 0,\n",
      " 'orgname>Davidson,': 0,\n",
      " 'orgname>Dickinson': 0,\n",
      " 'orgname>Kellogg': 0,\n",
      " 'orgname>Leason': 0,\n",
      " 'orgname>Peacock': 0,\n",
      " 'orgname>Wenzhou': 0,\n",
      " 'othercit>Dingo': 0,\n",
      " 'p': 28,\n",
      " 'parent-doc>': 0,\n",
      " 'parent-status>PENDING</parent-status>': 0,\n",
      " 'patcit': 73,\n",
      " 'primary-examiner>': 3,\n",
      " 'publication-reference>': 3,\n",
      " 'relation>': 0,\n",
      " 'residence>': 5,\n",
      " 'role>02</role>': 1,\n",
      " 'role>03</role>': 0,\n",
      " 'state>GA</state>': 1,\n",
      " 'state>MI</state>': 6,\n",
      " 'state>NJ</state>': 1,\n",
      " 'state>NY</state>': 0,\n",
      " 'us-applicant': 5,\n",
      " 'us-applicants>': 3,\n",
      " 'us-application-series-code>29</us-application-series-code>': 3,\n",
      " 'us-bibliographic-data-grant>': 3,\n",
      " 'us-citation>': 74,\n",
      " 'us-claim-statement>CLAIM</us-claim-statement>': 3,\n",
      " 'us-exemplary-claim>1</us-exemplary-claim>': 3,\n",
      " 'us-field-of-classification-search>': 3,\n",
      " 'us-parties>': 3,\n",
      " 'us-patent-grant': 3,\n",
      " 'us-references-cited>': 3,\n",
      " 'us-related-documents>': 0,\n",
      " 'us-term-of-grant>': 3}\n"
     ]
    }
   ],
   "source": [
    "#3. Quiz: Iterative Parsing\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "\n",
    "PATENTS = 'patent.data'\n",
    "\n",
    "def get_tag(line):\n",
    "    split_line = line.split()\n",
    "    return split_line[0][1:]\n",
    "\n",
    "def count_tags(filename):\n",
    "    result = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            #if not line.startswith(\"</\"):\n",
    "            tag = get_tag(line)\n",
    "            if tag[-1] != '>':\n",
    "                if tag not in result:\n",
    "                    result[tag] = 1\n",
    "                else:\n",
    "                    result[tag] += 1\n",
    "    return result\n",
    "            \n",
    "pprint.pprint(count_tags(PATENTS))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n"
     ]
    }
   ],
   "source": [
    "#6. Quiz: Tag Types\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into your database, you should check the\n",
    "\"k\" value for each \"<tag>\" and see if there are any potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data\n",
    "model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of\n",
    "four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "See the 'process_map' and 'test' functions for examples of the expected format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        non_lower = True\n",
    "        for c in element.attrib['k']:\n",
    "            if problemchars.search(c):\n",
    "                keys[\"problemchars\"] += 1\n",
    "                non_lower = False\n",
    "                break\n",
    "            elif lower_colon.search(c):\n",
    "                keys[\"lower_colon\"] += 1\n",
    "                non_lower = False\n",
    "                break\n",
    "            elif not lower.search(c):\n",
    "                keys['other'] += 1\n",
    "                non_lower = False\n",
    "                break\n",
    "        if non_lower:\n",
    "            keys['lower'] += 1    \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    keys = process_map('example.osm')\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n"
     ]
    }
   ],
   "source": [
    "#6. Quiz: Tag Types v.2\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into your database, you should check the\n",
    "\"k\" value for each \"<tag>\" and see if there are any potential problems.\n",
    "\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data\n",
    "model and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with\n",
    "problematic characters.\n",
    "\n",
    "Please complete the function 'key_type', such that we have a count of each of\n",
    "four tag categories in a dictionary:\n",
    "  \"lower\", for tags that contain only lowercase letters and are valid,\n",
    "  \"lower_colon\", for otherwise valid tags with a colon in their names,\n",
    "  \"problemchars\", for tags with problematic characters, and\n",
    "  \"other\", for other tags that do not fall into the other three categories.\n",
    "See the 'process_map' and 'test' functions for examples of the expected format.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        key = element.attrib['k']\n",
    "        if lower.search(key):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(key):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif re.findall(problemchars, key):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    keys = process_map('example.osm')\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['1219059', '147510', '26299', '451048', '567034', '939355'])\n"
     ]
    }
   ],
   "source": [
    "#7. Quiz: Exploring Users\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "\n",
    "def get_user(element):\n",
    "    if 'uid' in element.attrib:       \n",
    "        return element.attrib['uid']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        user = get_user(element)\n",
    "        if user:\n",
    "            users.add(user)\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map('example.osm')\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 6\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ave': set(['N. Lincoln Ave', 'North Lincoln Ave']),\n",
      " 'Rd.': set(['Baldwin Rd.']),\n",
      " 'St.': set(['West Lexington St.'])}\n",
      "N. Lincoln Ave => N. Lincoln Avenue\n",
      "North Lincoln Ave => North Lincoln Avenue\n",
      "West Lexington St. => West Lexington Street\n",
      "Baldwin Rd. => Baldwin Road\n"
     ]
    }
   ],
   "source": [
    "#10. Quiz: Improving Street Names\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"example13.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = {\"St\": \"Street\", \n",
    "           \"St.\": \"Street\",\n",
    "           \"Ave\": \"Avenue\",\n",
    "           \"Rd.\": \"Road\"\n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        name = name.replace(street_type, mapping[street_type])\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
